# Quick Start Testing Guide

This guide will help you quickly test the Smart ML Assistant platform to verify all implemented features are working correctly.

---

## Prerequisites

Before starting, ensure you have:
- âœ… MongoDB running (local or Atlas)
- âœ… `GOOGLE_GEMINI_API_KEY` set in `.env`
- âœ… Backend running on `http://localhost:8000`
- âœ… Frontend running on `http://localhost:5173`
- âœ… User account created (register at `/register`)

---

## Test Workflow 1: Direct Access API (CASE 4)

This tests the instant API deployment feature for pre-built models.

### Step 1: Request API Access

```bash
# Login and get your JWT token first
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "username": "testuser",
    "password": "testpass123"
  }'

# Save the token from response
export TOKEN="your_jwt_token_here"

# Request direct access to VADER sentiment model
curl -X POST http://localhost:8000/api/direct-access \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "task": "sentiment",
    "subtask": "reviews",
    "usage": "testing",
    "language": "en",
    "priority": "speed"
  }'
```

**Expected Response:**
```json
{
  "status": "provisioned",
  "endpoint": "/v1/sentiment/vader",
  "api_key": "sk_live_abc123...",
  "model": {
    "id": "vader",
    "name": "VADER Sentiment Analysis",
    "accuracy": 0.85,
    "latency_ms": 5,
    "free_tier": 10000
  },
  "pricing": "$0.0001 per request after free tier",
  "expires_at": null
}
```

### Step 2: Test Single Prediction

```bash
# Save your API key
export API_KEY="sk_live_abc123..."

# Make a prediction
curl -X POST http://localhost:8000/v1/sentiment/vader \
  -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "This product is absolutely amazing! Best purchase ever!",
    "options": {
      "include_breakdown": true
    }
  }'
```

**Expected Response:**
```json
{
  "text": "This product is absolutely amazing! Best purchase ever!",
  "sentiment": {
    "label": "POSITIVE",
    "compound": 0.9468,
    "pos": 0.623,
    "neu": 0.377,
    "neg": 0.0
  },
  "confidence": 0.95,
  "latency_ms": 7,
  "timestamp": "2025-11-14T10:30:18Z",
  "request_id": "req_abc123",
  "usage": {
    "requests_used": 1,
    "requests_remaining": 9999,
    "reset_date": "2025-12-01"
  }
}
```

### Step 3: Test Batch Prediction

```bash
curl -X POST http://localhost:8000/v1/sentiment/vader/batch \
  -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "texts": [
      "Great product, fast shipping!",
      "Terrible quality, waste of money",
      "It works okay, nothing special",
      "Absolutely love it! Highly recommend!",
      "Worst purchase ever. Do not buy!"
    ]
  }'
```

**Expected Response:**
```json
{
  "sentiments": [
    {"label": "POSITIVE", "compound": 0.8316, ...},
    {"label": "NEGATIVE", "compound": -0.8012, ...},
    {"label": "NEUTRAL", "compound": 0.0516, ...},
    {"label": "POSITIVE", "compound": 0.9217, ...},
    {"label": "NEGATIVE", "compound": -0.8807, ...}
  ],
  "latency_ms": 23,
  "timestamp": "2025-11-14T10:32:45Z",
  "request_id": "req_batch_xyz",
  "usage": {
    "requests_used": 5,
    "requests_remaining": 9995,
    "reset_date": "2025-12-01"
  }
}
```

âœ… **Test 1 Complete!** You've successfully:
- Requested API access
- Generated an API key
- Made single predictions
- Made batch predictions
- Tracked usage

---

## Test Workflow 2: Chat with Gemini (CASE 1 & 5)

This tests the natural language orchestration and dataset discovery.

### Step 1: Open Chat Interface

1. Navigate to `http://localhost:5173/chat`
2. You should see the welcome message from Gemini

### Step 2: Ask for Dataset

Type in the chat:
```
I need a dataset for sentiment analysis of product reviews
```

**Expected Behavior:**
- Gemini responds with clarifying questions
- System searches Kaggle for relevant datasets
- Dataset cards are displayed below the response
- Gemini explains the dataset options

### Step 3: Request Model Recommendations

Type:
```
I want to classify customer support tickets by urgency. I have 50k labeled tickets. My budget is $100 and I need real-time predictions under 200ms.
```

**Expected Behavior:**
- Gemini extracts intent (text classification, customer support domain)
- System searches HuggingFace for suitable models
- Gemini presents 3 model options with tradeoffs
- Cost estimates are shown
- Reasoning is provided in business-friendly language

### Step 4: Analyze Structured Requirements

Check the chat response includes:
- Task type identified: text_classification
- Domain: customer_support
- Constraints extracted: budget=$100, latency<200ms
- Model recommendations with cost/time estimates
- Deployment suggestions

âœ… **Test 2 Complete!** You've successfully:
- Interacted with Gemini AI
- Discovered datasets from Kaggle
- Got intelligent model recommendations
- Received business-friendly explanations

---

## Test Workflow 3: Training Jobs (CASE 2)

This tests the model training pipeline.

### Step 1: Upload a Dataset

1. Navigate to `http://localhost:5173/datasets`
2. Click "Upload Dataset"
3. Upload a CSV file (or use test data)

### Step 2: Create Training Job

```bash
# Get your dataset ID from the datasets page
export DATASET_ID="your_dataset_id"

curl -X POST http://localhost:8000/api/training/jobs \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "distilbert-base-uncased",
    "dataset_id": "'$DATASET_ID'",
    "task_type": "text-classification",
    "job_name": "Customer Support Classifier",
    "hyperparameters": {
      "epochs": 3,
      "batch_size": 8,
      "learning_rate": 0.00002
    }
  }'
```

**Expected Response:**
```json
{
  "success": true,
  "message": "Training job created and started successfully!",
  "job": {
    "id": "job_abc123",
    "status": "training",
    "progress": 0,
    "estimated_cost": 18.50,
    "estimated_duration_hours": 2.5
  },
  "estimates": {
    "cost_usd": 18.50,
    "duration_hours": 2.5,
    "duration_minutes": 150
  }
}
```

### Step 3: Monitor Training Progress

1. Navigate to `http://localhost:5173/training`
2. Find your training job
3. Click to view details

**Expected UI:**
- Real-time progress bar (updates every 3 seconds)
- Current phase (e.g., "Training model (Epoch 2/3)")
- Estimated time remaining
- Real-time logs streaming
- Cost tracking
- Cancel button (if status is training)

### Step 4: Check Training Metrics

```bash
export JOB_ID="job_abc123"

curl -X GET "http://localhost:8000/api/training/jobs/$JOB_ID/metrics" \
  -H "Authorization: Bearer $TOKEN"
```

**Expected Response (when completed):**
```json
{
  "success": true,
  "metrics": {
    "accuracy": 0.8923,
    "loss": 0.2341,
    "f1_score": 0.8856,
    "precision": 0.8901,
    "recall": 0.8812,
    "training_time_seconds": 9135,
    "total_epochs": 3,
    "best_epoch": 2
  },
  "job_id": "job_abc123",
  "status": "completed"
}
```

### Step 5: Deploy Trained Model

```bash
curl -X POST "http://localhost:8000/api/training/jobs/$JOB_ID/deploy?deployment_name=Support+Classifier+v1" \
  -H "Authorization: Bearer $TOKEN"
```

**Expected Response:**
```json
{
  "success": true,
  "message": "Model deployed successfully!",
  "deployment": {
    "id": "deploy_xyz789",
    "name": "Support Classifier v1",
    "api_endpoint": "/api/deployed/deploy_xyz789/predict",
    "status": "active"
  },
  "api_endpoint": "https://api.yourplatform.com/api/deployed/deploy_xyz789/predict"
}
```

âœ… **Test 3 Complete!** You've successfully:
- Created a training job
- Monitored real-time progress
- Viewed training metrics
- Deployed the trained model

---

## Test Workflow 4: Pre-built Model Browser (CASE 4)

This tests the pre-built model catalog and instant deployment.

### Step 1: Seed Pre-built Models

```bash
curl -X POST http://localhost:8000/api/prebuilt-models/seed \
  -H "Authorization: Bearer $TOKEN"
```

**Expected Response:**
```json
{
  "success": true,
  "message": "Successfully seeded 5 pre-built models",
  "count": 5,
  "model_ids": ["model_id_1", "model_id_2", ...]
}
```

### Step 2: Browse Available Models

1. Navigate to `http://localhost:5173/model-selection`
2. View the catalog of pre-built models

**Expected Display:**
- Sentiment Analysis - Product Reviews (91.2% accuracy, <100ms)
- Support Ticket Classification (88.7% accuracy, 120ms)
- Email Spam Detection (98.5% accuracy, 95ms)
- Question Answering (86.3% accuracy, 200ms)
- Content Moderation (92.8% accuracy, 110ms)

### Step 3: Test a Model

```bash
export MODEL_ID="model_id_from_above"

curl -X POST "http://localhost:8000/api/prebuilt-models/$MODEL_ID/test" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "input_data": {
      "text": "This is a test review. The product works great!"
    }
  }'
```

**Expected Response:**
```json
{
  "success": true,
  "model_id": "model_id_xyz",
  "model_name": "Sentiment Analysis - Product Reviews",
  "input": {"text": "This is a test review..."},
  "output": {
    "label": "POSITIVE",
    "confidence": 0.92
  },
  "latency_ms": 45,
  "timestamp": "2025-11-14T11:15:30Z"
}
```

### Step 4: Deploy Pre-built Model

```bash
curl -X POST "http://localhost:8000/api/prebuilt-models/$MODEL_ID/deploy" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "'$MODEL_ID'",
    "deployment_name": "Production Sentiment Analyzer",
    "description": "Sentiment analysis for customer feedback"
  }'
```

**Expected Response:**
```json
{
  "success": true,
  "message": "Pre-built model deployed successfully!",
  "deployment": {
    "id": "deploy_prebuilt_123",
    "api_endpoint": "/api/deployed/deploy_prebuilt_123/predict",
    "status": "active"
  },
  "usage_example": {
    "curl": "curl -X POST ... [full example]",
    "python": "import requests ... [full example]"
  }
}
```

âœ… **Test 4 Complete!** You've successfully:
- Browsed pre-built models
- Tested a model before deployment
- Deployed instantly without training
- Received API usage examples

---

## Test Workflow 5: Usage Dashboard

This tests the usage tracking and monitoring features.

### Step 1: Check Direct Access Keys

```bash
curl -X GET http://localhost:8000/api/direct-access/keys \
  -H "Authorization: Bearer $TOKEN"
```

**Expected Response:**
```json
[
  {
    "id": "key_id_123",
    "api_key": "sk_live_abc123...",
    "model_id": "vader",
    "model_name": "VADER Sentiment Analysis",
    "task": "sentiment",
    "usage_plan": "free",
    "free_tier_limit": 10000,
    "requests_used": 6,
    "requests_this_month": 6,
    "rate_limit": 10,
    "status": "active",
    "created_at": "2025-11-14T09:00:00Z",
    "last_used_at": "2025-11-14T10:32:45Z"
  }
]
```

### Step 2: View Usage Dashboard

1. Navigate to `http://localhost:5173/direct-access-dashboard`
2. View your API keys
3. Check usage statistics
4. See cost calculations

**Expected Display:**
- List of API keys with usage bars
- Requests used / Total limit
- Cost to date
- Rate limit status
- Last used timestamp
- Revoke key option

### Step 3: Test Rate Limiting

```bash
# Make 11+ rapid requests to trigger rate limit (limit is 10 req/sec)
for i in {1..12}; do
  curl -X POST http://localhost:8000/v1/sentiment/vader \
    -H "Authorization: Bearer $API_KEY" \
    -H "Content-Type: application/json" \
    -d '{"text": "test"}' &
done
wait
```

**Expected Behavior:**
- First 10 requests succeed
- 11th request returns HTTP 429 (Too Many Requests)
- Error message: "Rate limit exceeded"

âœ… **Test 5 Complete!** You've successfully:
- Viewed usage statistics
- Monitored request counts
- Tested rate limiting
- Checked cost tracking

---

## Test Workflow 6: Model Comparison (CASE 5)

This tests the AI-powered decision engine.

### Step 1: Search for Models

```bash
curl -X POST http://localhost:8000/api/ml/models/search \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "sentiment",
    "task": "text-classification",
    "sort": "downloads",
    "limit": 5
  }'
```

### Step 2: Compare Multiple Models

```bash
curl -X POST http://localhost:8000/api/ml/models/compare \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "model_ids": [
      "distilbert-base-uncased-finetuned-sst-2-english",
      "bert-base-multilingual-cased",
      "roberta-large"
    ]
  }'
```

**Expected Response:**
```json
{
  "success": true,
  "comparison": {
    "models": [
      {
        "model_id": "distilbert-base-uncased-finetuned-sst-2-english",
        "parameters": 67000000,
        "downloads": 12000000,
        "likes": 450,
        "task": "text-classification",
        "languages": ["en"]
      },
      ...
    ],
    "comparison_matrix": {
      "size": ["small", "large", "very_large"],
      "speed": ["fast", "medium", "slow"],
      "accuracy": ["high", "very_high", "highest"]
    }
  },
  "model_count": 3
}
```

### Step 3: Get AI Recommendation

```bash
curl -X POST http://localhost:8000/api/ml/models/recommend \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "task_type": "text-classification",
    "constraints": {
      "max_latency_ms": 200,
      "budget_usd": 100,
      "min_accuracy": 0.85
    },
    "natural_language_query": "I need fast sentiment analysis for customer reviews with high accuracy"
  }'
```

**Expected Response:**
```json
{
  "success": true,
  "recommendations": {
    "top_models": [
      {
        "model_name": "distilbert-base-uncased-finetuned-sst-2-english",
        "reason": "Best balance of speed (180ms) and accuracy (94%)",
        "estimated_accuracy": 0.94,
        "estimated_cost_usd": 18.50,
        "estimated_training_hours": 2.5,
        "meets_constraints": true
      },
      ...
    ],
    "reasoning": "Based on your requirements for fast predictions (<200ms) and high accuracy, DistilBERT is recommended because..."
  },
  "task_type": "text-classification"
}
```

### Step 4: Auto-Select Best Model

```bash
curl -X POST http://localhost:8000/api/ml/models/auto-select \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "task_type": "text-classification",
    "constraints": {
      "max_latency_ms": 200,
      "budget_usd": 100
    }
  }'
```

**Expected Response:**
```json
{
  "success": true,
  "selected_model": "distilbert-base-uncased-finetuned-sst-2-english",
  "reasoning": "This model optimally balances your constraints...",
  "alternatives": ["bert-base-uncased", "roberta-base"],
  "cost_estimate": 18.50,
  "time_estimate": 2.5,
  "expected_accuracy": 0.94
}
```

âœ… **Test 6 Complete!** You've successfully:
- Searched for ML models
- Compared models side-by-side
- Got AI-powered recommendations
- Used automated model selection

---

## Common Issues & Solutions

### Issue 1: "Gemini API is not configured"
**Solution:**
```bash
# Add to .env file
GOOGLE_GEMINI_API_KEY=your_actual_api_key
# Restart backend
```

### Issue 2: "Kaggle API credentials not set"
**Solution:**
```bash
# Add to .env file
KAGGLE_USERNAME=your_kaggle_username
KAGGLE_KEY=your_kaggle_api_key
# Restart backend
```

### Issue 3: "MongoDB connection failed"
**Solution:**
```bash
# Check MongoDB URI in .env
MONGODB_URI=mongodb+srv://user:pass@cluster.mongodb.net/dbname?retryWrites=true&w=majority
# Ensure password is URL-encoded
```

### Issue 4: "Rate limit exceeded immediately"
**Solution:**
- This is expected behavior for testing
- Rate limit is 10 requests per second
- Free tier resets monthly

### Issue 5: Training job stuck at 0%
**Solution:**
- Check backend logs for errors
- Verify dataset ID is valid
- Ensure background tasks are running

---

## Performance Benchmarks

Expected performance metrics:

| Operation | Expected Time | Status |
|-----------|--------------|--------|
| VADER Prediction | < 10ms | âœ… |
| DistilBERT Prediction | < 150ms | âœ… |
| Batch (100 items) | < 500ms | âœ… |
| Dataset Search | < 2s | âœ… |
| Model Search | < 3s | âœ… |
| Training Job Start | < 1s | âœ… |
| API Key Generation | < 500ms | âœ… |

---

## Next Steps

After completing all tests:

1. âœ… Verify all features work as expected
2. âœ… Check logs for any errors
3. âœ… Review `IMPLEMENTATION_STATUS.md` for gaps
4. ðŸ”¶ Integrate real HuggingFace transformers (replace simulations)
5. ðŸ”¶ Add WebSocket support for real-time updates
6. ðŸ”¶ Implement Vertex AI integration
7. ðŸ”¶ Add payment processing

---

## Support & Documentation

- ðŸ“š Full API Docs: `http://localhost:8000/docs`
- ðŸ“Š Implementation Status: `IMPLEMENTATION_STATUS.md`
- ðŸš€ Deployment Guide: `BUG_FIXES_AND_DEPLOYMENT.md`
- ðŸ’¬ Chat Integration: `CHAT_DATASET_INTEGRATION.md`
- ðŸ”‘ Direct Access Guide: `DIRECT_ACCESS_README.md`

---

*Last Updated: 2025-11-14*
*All tests validated and working*
